---
title: 'Denoising Diffusion Probabilistic Models - Paper breakdown'
date: 2024-07-04
permalink: /posts/2024/07/blog-post-1/
tags:
  - diffusion
  - ai
---

- [Overview](#overview)
- [Abstract](#abstract)
- [Introduction](#introduction)
- [Background](#background)
- [Diffusion models and denoising autoencoders](#diffusion-models-and-denoising-autoencoders)
  - [Forward process and L_T](#forward-process-and-l_t)
  - [Reverse process and L_1:T-1](#reverse-process-and-l_1t-1)
  - [Data scaling, reverse process decoder, and L_0](#data-scaling-reverse-process-decoder-and-l_0)
  - [Simplified training objective](#simplified-training-objective)
- [Experiments](#experiments)
  - [Sample Quality](#sample-quality)
  - [Reverse process parameterization and training objective ablation](#reverse-process-parameterization-and-training-objective-ablation)
  - [Progressive coding](#progressive-coding)
  - [Interpolation](#interpolation)
- [Related Works](#related-works)
- [Conclusion](#conclusion)

# Overview

Denoising Diffusion Probabilistic Models (DDPM for short) are the foundation for diffusion models. This blog post will breakdown the entire paper with commentary and additional images/videos in order to aide in understanding of all the maths and concepts.